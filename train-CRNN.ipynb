{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train-CRNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPs0U2b2cR4Vhosy/PHYgli",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satvik-venkatesh/audio-seg-data-synth/blob/main/train-CRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qRhBRa8Kw1X"
      },
      "source": [
        "# This notebook trains a convolutional recurrent neural network (CRNN) on the synthesised data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iQeu-LxPaeV",
        "outputId": "57008bce-2ad8-40a2-867b-2ff793a5733d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install sed_eval\n",
        "!pip install librosa==0.7.2\n",
        "!pip install soundfile"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sed_eval\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/b2/55591da46753ad1f1d375f5a0d1e12728ae9bf7270ecf47ff7fe902a4274/sed_eval-0.2.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from sed_eval) (1.18.5)\n",
            "Collecting dcase_util>=0.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/3e/e792e2298c4ed2649344846e13a3db722c0eea4b3b2216d29f1ec039de48/dcase_util-0.2.16.tar.gz (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.4.1)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (3.2.2)\n",
            "Collecting librosa>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/4d/c22d8ca74ca2c13cd4ac430fa353954886104321877b65fa871939e78591/librosa-0.8.0.tar.gz (183kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 25.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (1.15.0)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (0.16.0)\n",
            "Collecting soundfile>=0.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/f2/3cbbbf3b96fb9fa91582c438b574cff3f45b29c772f94c400e2c99ef5db9/SoundFile-0.10.3.post1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml>=3.11 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (3.13)\n",
            "Requirement already satisfied: requests>=2.12.4 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.11.2 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (4.41.1)\n",
            "Requirement already satisfied: pydot-ng>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from dcase_util>=0.2.4->sed_eval) (2.0.0)\n",
            "Collecting validators>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n",
            "Collecting python-magic>=0.4.13\n",
            "  Downloading https://files.pythonhosted.org/packages/59/77/c76dc35249df428ce2c38a3196e2b2e8f9d2f847a8ca1d4d7a3973c28601/python_magic-0.4.18-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->dcase_util>=0.2.4->sed_eval) (1.2.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (2.1.8)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.16.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.48.0)\n",
            "Collecting pooch>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/11/d7a1dc8173a4085759710e69aae6e070d0d432db84013c7c343e4e522b76/pooch-1.2.0-py3-none-any.whl (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (1.14.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.12.4->dcase_util>=0.2.4->sed_eval) (3.0.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (50.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (0.31.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pooch>=1.0->librosa>=0.7.0->dcase_util>=0.2.4->sed_eval) (20.4)\n",
            "Collecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->dcase_util>=0.2.4->sed_eval) (2.20)\n",
            "Building wheels for collected packages: sed-eval, dcase-util, librosa\n",
            "  Building wheel for sed-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sed-eval: filename=sed_eval-0.2.1-cp36-none-any.whl size=26125 sha256=a2e1b7f404946c1fd1695ea8970d72c9b3888c17a661367bb4a5829c2a715caa\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/72/5d/5fc941f98c583ce9d8adee7f13e24b46459aeded4125f9c369\n",
            "  Building wheel for dcase-util (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dcase-util: filename=dcase_util-0.2.16-cp36-none-any.whl size=2124352 sha256=5bd7faf1c0b22554f29696d8cea9c09adf841c89435d858ca731114ebe309e67\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/46/3b/1f9de1bd2ddfb9868bd7bf1cc38e83e42660fdfaacc6419bd0\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.8.0-cp36-none-any.whl size=201376 sha256=33ef38ea8fe0bb341153e678f4bdef900b2ce4de590fd0e346c8e3c298f5e5f5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/10/1e/382bb4369e189938d5c02e06d10c651817da8d485bfd1647c9\n",
            "Successfully built sed-eval dcase-util librosa\n",
            "Installing collected packages: soundfile, appdirs, pooch, librosa, validators, python-magic, dcase-util, sed-eval\n",
            "  Found existing installation: librosa 0.6.3\n",
            "    Uninstalling librosa-0.6.3:\n",
            "      Successfully uninstalled librosa-0.6.3\n",
            "Successfully installed appdirs-1.4.4 dcase-util-0.2.16 librosa-0.8.0 pooch-1.2.0 python-magic-0.4.18 sed-eval-0.2.1 soundfile-0.10.3.post1 validators-0.18.1\n",
            "Collecting librosa==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/b5/1817862d64a7c231afd15419d8418ae1f000742cac275e85c74b219cbccb/librosa-0.7.2.tar.gz (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (2.1.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.16.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (4.4.2)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (1.15.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.2.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.48.0)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from librosa==0.7.2) (0.10.3.post1)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.43.0->librosa==0.7.2) (50.3.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile>=0.9.0->librosa==0.7.2) (1.14.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2) (2.20)\n",
            "Building wheels for collected packages: librosa\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-cp36-none-any.whl size=1612885 sha256=a3089d895154ba675f9b83831965a8ebf2aca22218155169b8d144c069a9af38\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/6e/d7/bb93911540d2d1e44d690a1561871e5b6af82b69e80938abef\n",
            "Successfully built librosa\n",
            "Installing collected packages: librosa\n",
            "  Found existing installation: librosa 0.8.0\n",
            "    Uninstalling librosa-0.8.0:\n",
            "      Successfully uninstalled librosa-0.8.0\n",
            "Successfully installed librosa-0.7.2\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.6/dist-packages (0.10.3.post1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.6/dist-packages (from soundfile) (1.14.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0->soundfile) (2.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAr0CO_wC543"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import IPython\n",
        "import math\n",
        "import glob\n",
        "import sed_eval\n",
        "import dcase_util\n",
        "import pickle\n",
        "import os\n",
        "import soundfile as sf\n",
        "import librosa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2muBoiK7fMKP",
        "outputId": "b21c95c2-d19c-47f6-a81b-42e0bde88841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "Mount Google Drive into Colab.\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpjtJhW3kRPA",
        "outputId": "635c69ba-6ab1-48ad-d9e0-2908c06cdf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "\"\"\"\n",
        "Extract the .zip files into the 'train data' folder.\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "\n",
        "for i in range(0, 8):\n",
        "  zip_name = \"/content/drive/My Drive/Data Synthesis/Train - d_\" + str(i + 1) + \".zip\"\n",
        "  with ZipFile(zip_name, 'r') as zip:\n",
        "    zip.extractall('train data')\n",
        "    print(\"Extracted all sound files into the folder {}\".format(i + 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted all sound files into the folder 1\n",
            "Extracted all sound files into the folder 2\n",
            "Extracted all sound files into the folder 3\n",
            "Extracted all sound files into the folder 4\n",
            "Extracted all sound files into the folder 5\n",
            "Extracted all sound files into the folder 6\n",
            "Extracted all sound files into the folder 7\n",
            "Extracted all sound files into the folder 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuftbJJSC-oZ",
        "outputId": "d70a1b6e-dd36-411f-b062-0b0b63291072",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "Extracting BBC+MuSpeak Val data\n",
        "\"\"\"\n",
        "from zipfile import ZipFile\n",
        "zip_name = \"/content/drive/My Drive/Data Synthesis/Val - d.zip\"\n",
        "with ZipFile(zip_name, 'r') as zip:\n",
        "  zip.extractall('validation data')\n",
        "  print(\"Extracted all sound files into the folder\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracted all sound files into the folder\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ8m-5Kl7JAb"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "class DataGenerator(tf.compat.v2.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, list_examples, batch_size=128, dim=(1, ),\n",
        "                 n_classes=2, shuffle=True):\n",
        "        'Initialization'\n",
        "        print(\"Constructor called!!!\")\n",
        "        self.dim = dim\n",
        "        self.batch_size = batch_size\n",
        "        self.list_examples = list_examples\n",
        "        self.n_classes = n_classes\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        #print(\"The self.list_examples is {}\".format(self.list_examples))\n",
        "        return int(np.floor(len(self.list_examples) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "\n",
        "        # Find list of IDs\n",
        "        list_IDs_temp = [self.list_examples[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "      self.indexes = np.arange(len(self.list_examples))\n",
        "      if self.shuffle == True:\n",
        "          np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        # 'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
        "        # # Initialization\n",
        "\n",
        "        X = np.empty([self.batch_size, 802, 80], dtype=np.float32)\n",
        "        y = np.empty([self.batch_size, 802, 2], dtype=np.int16)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "\n",
        "            X[i,:, :] = np.load(ID[0])\n",
        "\n",
        "            # Store class          \n",
        "            y[i, :, :] = np.load(ID[1])\n",
        "\n",
        "        return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kh1_gI_vKMO"
      },
      "source": [
        "\"\"\"\n",
        "Functions to perform natural sort on the examples and labels.\n",
        "\"\"\"\n",
        "import re\n",
        "\n",
        "def tryint(s):\n",
        "    try:\n",
        "        return int(s)\n",
        "    except ValueError:\n",
        "        return s\n",
        "    \n",
        "def alphanum_key(s):\n",
        "    \"\"\" Turn a string into a list of string and number chunks.\n",
        "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
        "    \"\"\"\n",
        "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
        "\n",
        "def sort_nicely(l):\n",
        "    \"\"\" Sort the given list in the way that humans expect.\n",
        "    \"\"\"\n",
        "    l.sort(key=alphanum_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx3diPkTbs-W"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "\"\"\"\n",
        "Load the individual numpy arrays into partition\n",
        "\"\"\"\n",
        "data = glob.glob(\"/content/train data/content/Mel Files/**/mel-id-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/train data/content/Mel Files/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels)\n",
        "\n",
        "train_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(train_examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phPv7YAbej_-"
      },
      "source": [
        "\"\"\"\n",
        "Creating the train partition.\n",
        "\"\"\"\n",
        "m_train = 20480 * 2\n",
        "random.seed()\n",
        "random.shuffle(train_examples)\n",
        "\n",
        "data_MS = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-[0-9]*.npy\", recursive=True) \n",
        "sort_nicely(data_MS)\n",
        "\n",
        "labels_MS = glob.glob(\"/content/train data/MuSpeak/content/Mel Files/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels_MS)\n",
        "\n",
        "train_examples_MS = [(data_MS[i], labels_MS[i]) for i in range(len(data_MS))]\n",
        "\n",
        "partition = {}\n",
        "partition['train'] = train_examples[0:m_train] + train_examples_MS\n",
        "\n",
        "random.shuffle(partition['train'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXPkenT6d9iL",
        "outputId": "42d7273f-a449-4c6b-d9e2-2988ed7a8852",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The size of partition['train'] is {}\".format(len(partition['train'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of partition['train'] is 40960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sianBGv5hkr0",
        "outputId": "51d6d951-ae2e-4606-bc0b-f9684729a83c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "This loads data for the validation set.\n",
        "\"\"\"\n",
        "import glob\n",
        "import random\n",
        "\n",
        "data = glob.glob(\"/content/validation data/**/mel-id-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(data)\n",
        "\n",
        "labels = glob.glob(\"/content/validation data/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "sort_nicely(labels)\n",
        "\n",
        "validation_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "random.seed(4)\n",
        "random.shuffle(validation_examples)\n",
        "print(validation_examples[0])\n",
        "\n",
        "partition['validation'] = validation_examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('/content/validation data/content/Mel Files Val/block-id-4/mel-id-963.npy', '/content/validation data/content/Mel Files Val/block-id-4/mel-id-label-963.npy')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWAsqzHqmncM",
        "outputId": "19b839e7-eb45-4556-ca10-1629da543444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# \"\"\"\n",
        "# This loads data for the test set.\n",
        "# \"\"\"\n",
        "# import glob\n",
        "# import random\n",
        "\n",
        "# data = glob.glob(\"/content/test data/**/mel-id-[0-9]*.npy\", recursive=True)\n",
        "# sort_nicely(data)\n",
        "\n",
        "# labels = glob.glob(\"/content/test data/**/mel-id-label-[0-9]*.npy\", recursive=True)\n",
        "# sort_nicely(labels)\n",
        "\n",
        "# test_examples = [(data[i], labels[i]) for i in range(len(data))]\n",
        "\n",
        "# random.seed(4)\n",
        "# random.shuffle(test_examples)\n",
        "# print(test_examples[0])\n",
        "\n",
        "# partition['test'] = test_examples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('/content/test data/content/Mel Files Test/block-id-8/mel-id-2445.npy', '/content/test data/content/Mel Files Test/block-id-8/mel-id-label-2445.npy')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZzW248zAFTC",
        "outputId": "8286ee20-fc70-4b2a-b636-fff419f390a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Parameters\n",
        "params = {'dim': (1, ),\n",
        "          'batch_size': 128,\n",
        "          'n_classes': 2,\n",
        "          'shuffle': True}\n",
        "\n",
        "# Generators\n",
        "training_generator = DataGenerator(partition['train'], **params)\n",
        "validation_generator = DataGenerator(partition['validation'], **params)\n",
        "# test_generator = DataGenerator(partition['test'], **params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Constructor called!!!\n",
            "Constructor called!!!\n",
            "Constructor called!!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXJg3Gkm8JFq"
      },
      "source": [
        "import os\n",
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, model_path, patience=0):\n",
        "    super(MyCustomCallback, self).__init__()\n",
        "    self.patience = patience\n",
        "    # best_weights to store the weights at which the minimum loss occurs.\n",
        "    self.best_weights = None\n",
        "    self.model_path = model_path\n",
        " \n",
        "  def on_train_begin(self, logs=None):\n",
        "    # The number of epoch it has waited when loss is no longer minimum.\n",
        "    self.wait = 0\n",
        "    # The epoch the training stops at.\n",
        "    self.stopped_epoch = 0\n",
        "    # Initialize the best F1 as 0.0.\n",
        "    self.best_val_loss = np.inf\n",
        "    self.is_impatient = False\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    if not self.is_impatient:\n",
        "      print(\"Restoring model weights from the end of the best epoch.\")\n",
        "      self.model.set_weights(self.best_weights)\n",
        "      temp_model_path = self.model_path.replace(\".h5\", \"_temp.h5\")\n",
        "      os.remove(temp_model_path)\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    current_val_loss = logs.get(\"val_loss\")\n",
        "    print(\"\\n current_val_loss: {}\".format(current_val_loss))\n",
        "    temp_model_path = self.model_path.replace(\".h5\", \"_temp.h5\")\n",
        "    self.model.save(temp_model_path)\n",
        "    if current_val_loss < self.best_val_loss:\n",
        "      self.best_val_loss = current_val_loss\n",
        "      self.wait = 0\n",
        "      self.best_weights = self.model.get_weights()\n",
        "      self.model.save(self.model_path)\n",
        "\n",
        "    else:\n",
        "        self.wait += 1\n",
        "        if self.wait >= self.patience:\n",
        "            self.stopped_epoch = epoch\n",
        "            self.is_impatient = True\n",
        "            self.model.stop_training = True\n",
        "            print(\"Restoring model weights from the end of the best epoch.\")\n",
        "            self.model.set_weights(self.best_weights)\n",
        "            #os.remove(temp_model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbMh_ABBRv3y",
        "outputId": "756f3851-6f87-47b6-bce0-0258b8c4be0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "\"\"\"\n",
        "The CRNN developed for audio segmentation.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "mel_input = keras.Input(shape=(802, 80), name=\"mel_input\")\n",
        "X = mel_input\n",
        "\n",
        "X = tf.keras.layers.Reshape((802, 80, 1))(X)\n",
        "print(X.shape)\n",
        "\n",
        "X = tf.keras.layers.Conv2D(filters=16, kernel_size=7, strides=1, padding='same')(X)\n",
        "X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "X = tf.keras.layers.Activation('relu')(X)\n",
        "X = tf.keras.layers.MaxPool2D(pool_size=(1, 2))(X)\n",
        "X = tf.keras.layers.Dropout(rate = 0.2)(X)\n",
        "\n",
        "X = tf.keras.layers.Conv2D(filters=64, kernel_size=7, strides=1, padding='same')(X)\n",
        "X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "X = tf.keras.layers.Activation('relu')(X)\n",
        "X = tf.keras.layers.MaxPool2D(pool_size=(1, 2))(X)\n",
        "X = layers.Dropout(rate = 0.2)(X)\n",
        "\n",
        "print(X.shape)\n",
        "_, _, sx, sy = X.shape\n",
        "X = tf.keras.layers.Reshape((-1, int(sx * sy)))(X)\n",
        "\n",
        "X = layers.Bidirectional(layers.GRU(80, return_sequences = True))(X)\n",
        "X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "\n",
        "X = layers.Bidirectional(layers.GRU(80, return_sequences = True))(X)\n",
        "X = layers.BatchNormalization(momentum=0.0)(X)\n",
        "\n",
        "pred = layers.TimeDistributed(layers.Dense(2, activation='sigmoid'))(X)\n",
        "\n",
        "model = keras.Model(inputs = [mel_input], outputs = [pred])\n",
        "\n",
        "keras.utils.plot_model(model, \"CRNN.png\", show_shapes=True)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=[keras.losses.BinaryCrossentropy()], metrics=['binary_accuracy'] #, 'categorical_accuracy', tf.keras.metrics.Precision(class_id=0), tf.keras.metrics.Precision(class_id=1), tf.keras.metrics.Recall(class_id=0), tf.keras.metrics.Recall(class_id=1)]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 802, 80, 1)\n",
            "(None, 802, 20, 64)\n",
            "Model: \"functional_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "mel_input (InputLayer)       [(None, 802, 80)]         0         \n",
            "_________________________________________________________________\n",
            "reshape_2 (Reshape)          (None, 802, 80, 1)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 802, 80, 16)       800       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 802, 80, 16)       64        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 802, 80, 16)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 802, 40, 16)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 802, 40, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 802, 40, 64)       50240     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 802, 40, 64)       256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 802, 40, 64)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 802, 20, 64)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 802, 20, 64)       0         \n",
            "_________________________________________________________________\n",
            "reshape_3 (Reshape)          (None, 802, 1280)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 802, 160)          653760    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 802, 160)          640       \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 802, 160)          116160    \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 802, 160)          640       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 802, 2)            322       \n",
            "=================================================================\n",
            "Total params: 822,882\n",
            "Trainable params: 822,082\n",
            "Non-trainable params: 800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF_cdXjsdI6h"
      },
      "source": [
        "# Ensure the directory for the model path is already created.\n",
        "model_path = \"/content/drive/My Drive/model-1.h5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARrvIdEM_TCx"
      },
      "source": [
        "history = model.fit(training_generator, validation_data=validation_generator, epochs=30, \n",
        "                    callbacks=[MyCustomCallback(model_path, patience=15)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Lr0Fy5bTl0"
      },
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}